{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uDofnLo3FDbN",
        "outputId": "3c7a9e5c-4a62-414c-fc18-a9ba18cda480"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "%matplotlib inline\n",
        "# do the imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import KFold, GridSearchCV, train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras import layers\n",
        "from keras.optimizers import SGD\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f7Hs1j-bVnrU"
      },
      "outputs": [],
      "source": [
        "# set up the id block as a function\n",
        "def idBlock(x, filters, kernel_size):\n",
        "    # for the id block the short cut is just the input\n",
        "    shortcut = x\n",
        "\n",
        "    # since this is a resnet 18 we have two main blocks or sections\n",
        "    # we have a convoliutonal layer => batchnorm with a relu activation funding\n",
        "    x = layers.Conv2D(filters, kernel_size, padding='same', kernel_initializer='he_normal')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.ReLU()(x)\n",
        "\n",
        "    x = layers.Conv2D(filters, kernel_size, padding='same', kernel_initializer='he_normal')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    # here we add the shortcut with the output of the layers => this is like the skip connection!\n",
        "    x = layers.Add()([x, shortcut])\n",
        "    x = layers.ReLU()(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "# this is the convolutional block\n",
        "# this has the same connection skipping that the id block has but it changes the dimensions\n",
        "def convBlock(x, filters, kernel_size, stride):\n",
        "\n",
        "    # first lets save the shortcut like before so we can use it at the end to add them\n",
        "    # to get the skip connection\n",
        "    shortcut = layers.Conv2D(filters, kernel_size=1, strides=stride, padding='same', kernel_initializer='he_normal')(x)\n",
        "    shortcut = layers.BatchNormalization()(shortcut)\n",
        "\n",
        "    # now we have that first convolutional layer\n",
        "    # for this one we keep the same stide as the shortcut => this is to maintain the same space\n",
        "    x = layers.Conv2D(filters, kernel_size, strides=stride, padding='same', kernel_initializer='he_normal')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.ReLU()(x)\n",
        "\n",
        "    # like the id block since this is a resnet-18 we have to convo sets => same as above essentially\n",
        "    x = layers.Conv2D(filters, kernel_size, padding='same', kernel_initializer='he_normal')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    # now we can add to get that skip connection\n",
        "    x = layers.Add()([x, shortcut])\n",
        "    x = layers.ReLU()(x)\n",
        "\n",
        "    return x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "maviAPG0YGr6"
      },
      "source": [
        "https://medium.com/analytics-vidhya/understanding-and-implementation-of-residual-networks-resnets-b80f9a507b9c\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t0882YhpVfJb"
      },
      "outputs": [],
      "source": [
        "def create_RESNET_18(input_shape, num_classes):\n",
        "    # get the inputs\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "\n",
        "    # this is the 1/5 stage\n",
        "    x = layers.Conv2D(64, kernel_size=7, strides=2, padding='same', kernel_initializer='he_normal')(inputs)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.ReLU()(x)\n",
        "    x = layers.MaxPooling2D(pool_size=3, strides=2, padding='same')(x)\n",
        "\n",
        "    # 2/5 stage\n",
        "    x = convBlock(x, filters=64, kernel_size=3, stride=1)\n",
        "    x = idBlock(x, filters=64, kernel_size=3)\n",
        "\n",
        "    # 3/5 stage\n",
        "    x = convBlock(x, filters=128, kernel_size=3, stride=2)\n",
        "    x = idBlock(x, filters=128, kernel_size=3)\n",
        "\n",
        "    # 4/5 stage\n",
        "    x = convBlock(x, filters=256, kernel_size=3, stride=2)\n",
        "    x = idBlock(x, filters=256, kernel_size=3)\n",
        "\n",
        "    # 5/5 stage\n",
        "    x = convBlock(x, filters=512, kernel_size=3, stride=2)\n",
        "    x = idBlock(x, filters=512, kernel_size=3)\n",
        "\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "    x = layers.Dense(num_classes, activation='softmax', kernel_initializer='he_normal')(x)\n",
        "\n",
        "    model = tf.keras.Model(inputs=inputs, outputs=x, name='ResNet')\n",
        "\n",
        "    model.compile(\n",
        "      optimizer = 'adam',\n",
        "      loss = \"sparse_categorical_crossentropy\",\n",
        "      metrics = ['accuracy']\n",
        "    )\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pnnWOIpIa2xz",
        "outputId": "083ef974-15f7-4487-bf59-8fe166566bcc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 485 files belonging to 3 classes.\n"
          ]
        }
      ],
      "source": [
        "# read in the data\n",
        "# main directory is from my google drive\n",
        "# load the images with TensorFlow => labels are inferred from directory strcture\n",
        "def readData():\n",
        "  main_directory = '/content/drive/My Drive/week_1_data'\n",
        "\n",
        "  dataset = tf.keras.utils.image_dataset_from_directory(\n",
        "      main_directory,\n",
        "      labels='inferred',\n",
        "      label_mode='int',\n",
        "      image_size=(128, 128),\n",
        "      batch_size=32,\n",
        "      shuffle=True\n",
        "  )\n",
        "\n",
        "  # iterate through the images/labels for each batch\n",
        "  # append the data/labels to each list so we can concatenate them into np arrays\n",
        "  images = []\n",
        "  labels = []\n",
        "  for image_batch, label_batch in dataset:\n",
        "      images.append(image_batch.numpy())\n",
        "      labels.append(label_batch.numpy())\n",
        "  return np.concatenate(images), np.concatenate(labels)\n",
        "\n",
        "images, labels = readData()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ejaKFavwVmHe",
        "outputId": "6547e933-a555-4428-b416-9340745dae3e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/14\n",
            "25/25 [==============================] - 16s 39ms/step - loss: 1.4543 - accuracy: 0.5387\n",
            "Epoch 2/14\n",
            "25/25 [==============================] - 1s 33ms/step - loss: 0.8234 - accuracy: 0.6701\n",
            "Epoch 3/14\n",
            "25/25 [==============================] - 1s 35ms/step - loss: 0.8480 - accuracy: 0.6521\n",
            "Epoch 4/14\n",
            "25/25 [==============================] - 1s 38ms/step - loss: 0.6805 - accuracy: 0.6856\n",
            "Epoch 5/14\n",
            "25/25 [==============================] - 1s 32ms/step - loss: 0.5574 - accuracy: 0.7680\n",
            "Epoch 6/14\n",
            "25/25 [==============================] - 1s 32ms/step - loss: 0.4917 - accuracy: 0.7964\n",
            "Epoch 7/14\n",
            "25/25 [==============================] - 1s 32ms/step - loss: 0.3428 - accuracy: 0.8660\n",
            "Epoch 8/14\n",
            "25/25 [==============================] - 1s 34ms/step - loss: 0.3473 - accuracy: 0.8763\n",
            "Epoch 9/14\n",
            "25/25 [==============================] - 1s 42ms/step - loss: 0.4657 - accuracy: 0.8170\n",
            "Epoch 10/14\n",
            "25/25 [==============================] - 1s 35ms/step - loss: 0.4101 - accuracy: 0.8479\n",
            "Epoch 11/14\n",
            "25/25 [==============================] - 1s 36ms/step - loss: 0.2477 - accuracy: 0.9227\n",
            "Epoch 12/14\n",
            "25/25 [==============================] - 1s 32ms/step - loss: 0.2852 - accuracy: 0.9046\n",
            "Epoch 13/14\n",
            "25/25 [==============================] - 1s 33ms/step - loss: 0.2896 - accuracy: 0.8943\n",
            "Epoch 14/14\n",
            "25/25 [==============================] - 1s 33ms/step - loss: 0.2058 - accuracy: 0.9381\n",
            "4/4 [==============================] - 1s 21ms/step - loss: 0.5326 - accuracy: 0.7835\n",
            "Test accuracy: 0.7835051417350769\n"
          ]
        }
      ],
      "source": [
        "# Define input shape based on your image data\n",
        "input_shape = (128, 128, 3)\n",
        "num_classes = 3\n",
        "\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
        "model = create_RESNET_18(input_shape, num_classes)\n",
        "model.fit(x_train, y_train, epochs=14, batch_size=16)\n",
        "loss, accuracy = model.evaluate(x_test, y_test)\n",
        "print(f'Test accuracy: {accuracy}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t5yNgzaodpQp"
      },
      "source": [
        "Epoch 1/15\n",
        "25/25 [==============================] - 12s 34ms/step - loss: 1.6721 - accuracy: 0.5180\n",
        "Epoch 2/15\n",
        "25/25 [==============================] - 1s 31ms/step - loss: 0.9693 - accuracy: 0.5979\n",
        "Epoch 3/15\n",
        "25/25 [==============================] - 1s 31ms/step - loss: 0.7303 - accuracy: 0.6649\n",
        "Epoch 4/15\n",
        "25/25 [==============================] - 1s 34ms/step - loss: 0.5590 - accuracy: 0.7526\n",
        "Epoch 5/15\n",
        "25/25 [==============================] - 1s 34ms/step - loss: 0.4666 - accuracy: 0.8119\n",
        "Epoch 6/15\n",
        "25/25 [==============================] - 1s 34ms/step - loss: 0.4440 - accuracy: 0.8273\n",
        "Epoch 7/15\n",
        "25/25 [==============================] - 1s 35ms/step - loss: 0.3770 - accuracy: 0.8557\n",
        "Epoch 8/15\n",
        "25/25 [==============================] - 1s 31ms/step - loss: 0.2936 - accuracy: 0.8866\n",
        "Epoch 9/15\n",
        "25/25 [==============================] - 1s 31ms/step - loss: 0.2487 - accuracy: 0.9201\n",
        "Epoch 10/15\n",
        "25/25 [==============================] - 1s 31ms/step - loss: 0.1591 - accuracy: 0.9278\n",
        "Epoch 11/15\n",
        "25/25 [==============================] - 1s 31ms/step - loss: 0.3013 - accuracy: 0.8840\n",
        "Epoch 12/15\n",
        "25/25 [==============================] - 1s 31ms/step - loss: 0.3406 - accuracy: 0.8892\n",
        "Epoch 13/15\n",
        "25/25 [==============================] - 1s 31ms/step - loss: 0.2950 - accuracy: 0.9072\n",
        "Epoch 14/15\n",
        "25/25 [==============================] - 1s 31ms/step - loss: 0.1865 - accuracy: 0.9330\n",
        "Epoch 15/15\n",
        "25/25 [==============================] - 1s 31ms/step - loss: 0.1381 - accuracy: 0.9459\n",
        "4/4 [==============================] - 1s 20ms/step - loss: 1.0111 - accuracy: 0.7629\n",
        "Test accuracy: 0.7628865838050842\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
